{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "1c24147b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler, OrdinalEncoder\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.multioutput import MultiOutputRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "import joblib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3cb1fb53",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape: (97297, 33)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Age</th>\n",
       "      <th>gender</th>\n",
       "      <th>ethnicity</th>\n",
       "      <th>education_level</th>\n",
       "      <th>income_level</th>\n",
       "      <th>employment_status</th>\n",
       "      <th>smoking_status</th>\n",
       "      <th>alcohol_consumption_per_week</th>\n",
       "      <th>physical_activity_minutes_per_week</th>\n",
       "      <th>diet_score</th>\n",
       "      <th>...</th>\n",
       "      <th>triglycerides</th>\n",
       "      <th>glucose_fasting</th>\n",
       "      <th>glucose_postprandial</th>\n",
       "      <th>insulin_level</th>\n",
       "      <th>hba1c</th>\n",
       "      <th>diabetes_risk</th>\n",
       "      <th>hypertension_risk</th>\n",
       "      <th>heart_disease_risk</th>\n",
       "      <th>obesity_risk</th>\n",
       "      <th>cholesterol_imbalance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>58</td>\n",
       "      <td>Male</td>\n",
       "      <td>Asian</td>\n",
       "      <td>Highschool</td>\n",
       "      <td>Lower-Middle</td>\n",
       "      <td>Employed</td>\n",
       "      <td>Never</td>\n",
       "      <td>0</td>\n",
       "      <td>215</td>\n",
       "      <td>5.7</td>\n",
       "      <td>...</td>\n",
       "      <td>145</td>\n",
       "      <td>136</td>\n",
       "      <td>236</td>\n",
       "      <td>6.36</td>\n",
       "      <td>8.18</td>\n",
       "      <td>80</td>\n",
       "      <td>80</td>\n",
       "      <td>20</td>\n",
       "      <td>50</td>\n",
       "      <td>80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>52</td>\n",
       "      <td>Female</td>\n",
       "      <td>White</td>\n",
       "      <td>Highschool</td>\n",
       "      <td>Middle</td>\n",
       "      <td>Employed</td>\n",
       "      <td>Former</td>\n",
       "      <td>1</td>\n",
       "      <td>143</td>\n",
       "      <td>6.7</td>\n",
       "      <td>...</td>\n",
       "      <td>30</td>\n",
       "      <td>93</td>\n",
       "      <td>150</td>\n",
       "      <td>2.00</td>\n",
       "      <td>5.63</td>\n",
       "      <td>20</td>\n",
       "      <td>50</td>\n",
       "      <td>20</td>\n",
       "      <td>20</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>60</td>\n",
       "      <td>Male</td>\n",
       "      <td>Hispanic</td>\n",
       "      <td>Highschool</td>\n",
       "      <td>Middle</td>\n",
       "      <td>Unemployed</td>\n",
       "      <td>Never</td>\n",
       "      <td>1</td>\n",
       "      <td>57</td>\n",
       "      <td>6.4</td>\n",
       "      <td>...</td>\n",
       "      <td>36</td>\n",
       "      <td>118</td>\n",
       "      <td>195</td>\n",
       "      <td>5.07</td>\n",
       "      <td>7.51</td>\n",
       "      <td>80</td>\n",
       "      <td>50</td>\n",
       "      <td>20</td>\n",
       "      <td>20</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>74</td>\n",
       "      <td>Female</td>\n",
       "      <td>Black</td>\n",
       "      <td>Highschool</td>\n",
       "      <td>Low</td>\n",
       "      <td>Retired</td>\n",
       "      <td>Never</td>\n",
       "      <td>0</td>\n",
       "      <td>49</td>\n",
       "      <td>3.4</td>\n",
       "      <td>...</td>\n",
       "      <td>140</td>\n",
       "      <td>139</td>\n",
       "      <td>253</td>\n",
       "      <td>5.28</td>\n",
       "      <td>9.03</td>\n",
       "      <td>80</td>\n",
       "      <td>20</td>\n",
       "      <td>20</td>\n",
       "      <td>80</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>46</td>\n",
       "      <td>Male</td>\n",
       "      <td>White</td>\n",
       "      <td>Graduate</td>\n",
       "      <td>Middle</td>\n",
       "      <td>Retired</td>\n",
       "      <td>Never</td>\n",
       "      <td>1</td>\n",
       "      <td>109</td>\n",
       "      <td>7.2</td>\n",
       "      <td>...</td>\n",
       "      <td>160</td>\n",
       "      <td>137</td>\n",
       "      <td>184</td>\n",
       "      <td>12.74</td>\n",
       "      <td>7.20</td>\n",
       "      <td>80</td>\n",
       "      <td>50</td>\n",
       "      <td>20</td>\n",
       "      <td>20</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 33 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Age  gender ethnicity education_level  income_level employment_status  \\\n",
       "0   58    Male     Asian      Highschool  Lower-Middle          Employed   \n",
       "1   52  Female     White      Highschool        Middle          Employed   \n",
       "2   60    Male  Hispanic      Highschool        Middle        Unemployed   \n",
       "3   74  Female     Black      Highschool           Low           Retired   \n",
       "4   46    Male     White        Graduate        Middle           Retired   \n",
       "\n",
       "  smoking_status  alcohol_consumption_per_week  \\\n",
       "0          Never                             0   \n",
       "1         Former                             1   \n",
       "2          Never                             1   \n",
       "3          Never                             0   \n",
       "4          Never                             1   \n",
       "\n",
       "   physical_activity_minutes_per_week  diet_score  ...  triglycerides  \\\n",
       "0                                 215         5.7  ...            145   \n",
       "1                                 143         6.7  ...             30   \n",
       "2                                  57         6.4  ...             36   \n",
       "3                                  49         3.4  ...            140   \n",
       "4                                 109         7.2  ...            160   \n",
       "\n",
       "   glucose_fasting  glucose_postprandial  insulin_level  hba1c  diabetes_risk  \\\n",
       "0              136                   236           6.36   8.18             80   \n",
       "1               93                   150           2.00   5.63             20   \n",
       "2              118                   195           5.07   7.51             80   \n",
       "3              139                   253           5.28   9.03             80   \n",
       "4              137                   184          12.74   7.20             80   \n",
       "\n",
       "   hypertension_risk  heart_disease_risk  obesity_risk  cholesterol_imbalance  \n",
       "0                 80                  20            50                     80  \n",
       "1                 50                  20            20                     20  \n",
       "2                 50                  20            20                     20  \n",
       "3                 20                  20            80                     20  \n",
       "4                 50                  20            20                     20  \n",
       "\n",
       "[5 rows x 33 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load\n",
    "df = pd.read_csv(\"/Users/tanya-mac/Desktop/Health Risk Predictor from Lifestyle & Medical History/data/processed/model_dataset.csv\")\n",
    "print('Shape:', df.shape)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5df77501",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(97297, 33)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fb9d4b98",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separate features (X) and targets (y)\n",
    "\n",
    "X = df.drop(columns=[\n",
    "    'diabetes_risk',\n",
    "    'hypertension_risk',\n",
    "    'heart_disease_risk',\n",
    "    'obesity_risk',\n",
    "    'cholesterol_imbalance'\n",
    "])\n",
    "\n",
    "y = df[[\n",
    "    'diabetes_risk',\n",
    "    'hypertension_risk',\n",
    "    'heart_disease_risk',\n",
    "    'obesity_risk',\n",
    "    'cholesterol_imbalance'\n",
    "]]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8b1e5fa0",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f791e735",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Age</th>\n",
       "      <th>gender</th>\n",
       "      <th>ethnicity</th>\n",
       "      <th>education_level</th>\n",
       "      <th>income_level</th>\n",
       "      <th>employment_status</th>\n",
       "      <th>smoking_status</th>\n",
       "      <th>alcohol_consumption_per_week</th>\n",
       "      <th>physical_activity_minutes_per_week</th>\n",
       "      <th>diet_score</th>\n",
       "      <th>...</th>\n",
       "      <th>triglycerides</th>\n",
       "      <th>glucose_fasting</th>\n",
       "      <th>glucose_postprandial</th>\n",
       "      <th>insulin_level</th>\n",
       "      <th>hba1c</th>\n",
       "      <th>diabetes_risk</th>\n",
       "      <th>hypertension_risk</th>\n",
       "      <th>heart_disease_risk</th>\n",
       "      <th>obesity_risk</th>\n",
       "      <th>cholesterol_imbalance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>58</td>\n",
       "      <td>Male</td>\n",
       "      <td>Asian</td>\n",
       "      <td>Highschool</td>\n",
       "      <td>Lower-Middle</td>\n",
       "      <td>Employed</td>\n",
       "      <td>Never</td>\n",
       "      <td>0</td>\n",
       "      <td>215</td>\n",
       "      <td>5.7</td>\n",
       "      <td>...</td>\n",
       "      <td>145</td>\n",
       "      <td>136</td>\n",
       "      <td>236</td>\n",
       "      <td>6.36</td>\n",
       "      <td>8.18</td>\n",
       "      <td>80</td>\n",
       "      <td>80</td>\n",
       "      <td>20</td>\n",
       "      <td>50</td>\n",
       "      <td>80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>52</td>\n",
       "      <td>Female</td>\n",
       "      <td>White</td>\n",
       "      <td>Highschool</td>\n",
       "      <td>Middle</td>\n",
       "      <td>Employed</td>\n",
       "      <td>Former</td>\n",
       "      <td>1</td>\n",
       "      <td>143</td>\n",
       "      <td>6.7</td>\n",
       "      <td>...</td>\n",
       "      <td>30</td>\n",
       "      <td>93</td>\n",
       "      <td>150</td>\n",
       "      <td>2.00</td>\n",
       "      <td>5.63</td>\n",
       "      <td>20</td>\n",
       "      <td>50</td>\n",
       "      <td>20</td>\n",
       "      <td>20</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>60</td>\n",
       "      <td>Male</td>\n",
       "      <td>Hispanic</td>\n",
       "      <td>Highschool</td>\n",
       "      <td>Middle</td>\n",
       "      <td>Unemployed</td>\n",
       "      <td>Never</td>\n",
       "      <td>1</td>\n",
       "      <td>57</td>\n",
       "      <td>6.4</td>\n",
       "      <td>...</td>\n",
       "      <td>36</td>\n",
       "      <td>118</td>\n",
       "      <td>195</td>\n",
       "      <td>5.07</td>\n",
       "      <td>7.51</td>\n",
       "      <td>80</td>\n",
       "      <td>50</td>\n",
       "      <td>20</td>\n",
       "      <td>20</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>74</td>\n",
       "      <td>Female</td>\n",
       "      <td>Black</td>\n",
       "      <td>Highschool</td>\n",
       "      <td>Low</td>\n",
       "      <td>Retired</td>\n",
       "      <td>Never</td>\n",
       "      <td>0</td>\n",
       "      <td>49</td>\n",
       "      <td>3.4</td>\n",
       "      <td>...</td>\n",
       "      <td>140</td>\n",
       "      <td>139</td>\n",
       "      <td>253</td>\n",
       "      <td>5.28</td>\n",
       "      <td>9.03</td>\n",
       "      <td>80</td>\n",
       "      <td>20</td>\n",
       "      <td>20</td>\n",
       "      <td>80</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>46</td>\n",
       "      <td>Male</td>\n",
       "      <td>White</td>\n",
       "      <td>Graduate</td>\n",
       "      <td>Middle</td>\n",
       "      <td>Retired</td>\n",
       "      <td>Never</td>\n",
       "      <td>1</td>\n",
       "      <td>109</td>\n",
       "      <td>7.2</td>\n",
       "      <td>...</td>\n",
       "      <td>160</td>\n",
       "      <td>137</td>\n",
       "      <td>184</td>\n",
       "      <td>12.74</td>\n",
       "      <td>7.20</td>\n",
       "      <td>80</td>\n",
       "      <td>50</td>\n",
       "      <td>20</td>\n",
       "      <td>20</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 33 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Age  gender ethnicity education_level  income_level employment_status  \\\n",
       "0   58    Male     Asian      Highschool  Lower-Middle          Employed   \n",
       "1   52  Female     White      Highschool        Middle          Employed   \n",
       "2   60    Male  Hispanic      Highschool        Middle        Unemployed   \n",
       "3   74  Female     Black      Highschool           Low           Retired   \n",
       "4   46    Male     White        Graduate        Middle           Retired   \n",
       "\n",
       "  smoking_status  alcohol_consumption_per_week  \\\n",
       "0          Never                             0   \n",
       "1         Former                             1   \n",
       "2          Never                             1   \n",
       "3          Never                             0   \n",
       "4          Never                             1   \n",
       "\n",
       "   physical_activity_minutes_per_week  diet_score  ...  triglycerides  \\\n",
       "0                                 215         5.7  ...            145   \n",
       "1                                 143         6.7  ...             30   \n",
       "2                                  57         6.4  ...             36   \n",
       "3                                  49         3.4  ...            140   \n",
       "4                                 109         7.2  ...            160   \n",
       "\n",
       "   glucose_fasting  glucose_postprandial  insulin_level  hba1c  diabetes_risk  \\\n",
       "0              136                   236           6.36   8.18             80   \n",
       "1               93                   150           2.00   5.63             20   \n",
       "2              118                   195           5.07   7.51             80   \n",
       "3              139                   253           5.28   9.03             80   \n",
       "4              137                   184          12.74   7.20             80   \n",
       "\n",
       "   hypertension_risk  heart_disease_risk  obesity_risk  cholesterol_imbalance  \n",
       "0                 80                  20            50                     80  \n",
       "1                 50                  20            20                     20  \n",
       "2                 50                  20            20                     20  \n",
       "3                 20                  20            80                     20  \n",
       "4                 50                  20            20                     20  \n",
       "\n",
       "[5 rows x 33 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "66c26dfa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "education_level\n",
       "Highschool      43651\n",
       "Graduate        34097\n",
       "Postgraduate    14552\n",
       "No formal        4997\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['education_level'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "117a152b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "smoking_status\n",
       "Never      58218\n",
       "Current    19591\n",
       "Former     19488\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['smoking_status'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f85a3e46",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "income_level\n",
       "Middle          34214\n",
       "Lower-Middle    24467\n",
       "Upper-Middle    19334\n",
       "Low             14422\n",
       "High             4860\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['income_level'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "13858d6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import OneHotEncoder, OrdinalEncoder\n",
    "\n",
    "# Nominal categorical features → OneHotEncoding\n",
    "categorical_features_nominal = [\n",
    "    'gender',\n",
    "    'ethnicity',\n",
    "    'employment_status',\n",
    "    'smoking_status'\n",
    "]\n",
    "\n",
    "# Ordinal categorical features → OrdinalEncoding\n",
    "categorical_features_ordinal = [\n",
    "    'education_level',\n",
    "    'income_level'\n",
    "]\n",
    "\n",
    "# Define the ordering for ordinal encode\n",
    "education_order = [\n",
    "    [\"No formal\", \"Highschool\", \"Graduate\", \"Postgraduate\"]\n",
    "]\n",
    "\n",
    "income_order = [\n",
    "    [\"Low\", \"Lower-Middle\", \"Middle\", \"Upper-Middle\", \"High\"]\n",
    "]\n",
    "\n",
    "# Preprocessor\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('ohe_cat', OneHotEncoder(sparse_output=False, handle_unknown='ignore'),\n",
    "         categorical_features_nominal),\n",
    "\n",
    "        ('ord_cat', OrdinalEncoder(\n",
    "            categories=education_order + income_order),\n",
    "         categorical_features_ordinal)\n",
    "    ],\n",
    "    remainder='passthrough'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "c0f6ad98",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------- 5) Model definition ----------\n",
    "base_rf = RandomForestRegressor(\n",
    "    n_estimators=200,\n",
    "    random_state=42,\n",
    "    n_jobs=-1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "2de42e25",
   "metadata": {},
   "outputs": [],
   "source": [
    "multi_model = MultiOutputRegressor(base_rf, n_jobs=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "d901f7f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe = Pipeline([\n",
    "    ('preprocess', preprocessor),\n",
    "    ('model', multi_model)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "2fe4d8f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting pipeline ...\n",
      "Training finished.\n"
     ]
    }
   ],
   "source": [
    "print(\"Fitting pipeline ...\")\n",
    "pipe.fit(X_train, y_train)\n",
    "print(\"Training finished.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "301549fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = pipe.predict(X_test)  # shape (n_samples, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "c2bc74e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "target_cols = [\n",
    "    'diabetes_risk',\n",
    "    'hypertension_risk',\n",
    "    'heart_disease_risk',\n",
    "    'obesity_risk',\n",
    "    'cholesterol_imbalance'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "5809d3c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_multioutput_regressor.py\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import OneHotEncoder, OrdinalEncoder\n",
    "from sklearn.multioutput import MultiOutputRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "import joblib\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "f298a3f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "diabetes_risk -> MAE: 8.155, RMSE: 15.484, R2: 0.722\n",
      "hypertension_risk -> MAE: 0.000, RMSE: 0.000, R2: 1.000\n",
      "heart_disease_risk -> MAE: 0.021, RMSE: 0.688, R2: 0.998\n",
      "obesity_risk -> MAE: 0.000, RMSE: 0.000, R2: 1.000\n",
      "cholesterol_imbalance -> MAE: 0.000, RMSE: 0.000, R2: 1.000\n",
      "Mean MAE across targets: 1.635\n"
     ]
    }
   ],
   "source": [
    "metrics = {}\n",
    "for i, col in enumerate(target_cols):\n",
    "    mae = mean_absolute_error(y_test.iloc[:, i], y_pred[:, i])\n",
    "    rmse = np.sqrt(mean_squared_error(y_test.iloc[:, i], y_pred[:, i] ))\n",
    "    r2 = r2_score(y_test.iloc[:, i], y_pred[:, i])\n",
    "    metrics[col] = {\"MAE\": mae, \"RMSE\": rmse, \"R2\": r2}\n",
    "    print(f\"{col} -> MAE: {mae:.3f}, RMSE: {rmse:.3f}, R2: {r2:.3f}\")\n",
    "\n",
    "# overall (mean MAE)\n",
    "mean_mae = np.mean([m[\"MAE\"] for m in metrics.values()])\n",
    "print(f\"Mean MAE across targets: {mean_mae:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "cdea0451",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/h2/3jh9mwk53cg6z20yjs0w4hp00000gn/T/ipykernel_2446/847723935.py:16: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  pred_cat_df = pred_df.applymap(categorize)\n"
     ]
    }
   ],
   "source": [
    "# ---------- 10) Convert numeric predictions to categories ----------\n",
    "def categorize(pct):\n",
    "    # pct assumed 0..100\n",
    "    if np.isnan(pct):\n",
    "        return None\n",
    "    if pct < 30:\n",
    "        return \"Low\"\n",
    "    elif pct < 55:\n",
    "        return \"Moderate\"\n",
    "    elif pct < 75:\n",
    "        return \"High\"\n",
    "    else:\n",
    "        return \"Very High\"\n",
    "\n",
    "pred_df = pd.DataFrame(y_pred, columns=target_cols, index=X_test.index)\n",
    "pred_cat_df = pred_df.applymap(categorize)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "275b48a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Sample predictions (first 5 rows):\n",
      "   diabetes_risk  hypertension_risk  heart_disease_risk  obesity_risk  \\\n",
      "0           20.0               80.0                20.0          20.0   \n",
      "1           80.0               80.0                20.0          20.0   \n",
      "2           20.0               80.0                20.0          50.0   \n",
      "3           20.0               50.0                20.0          20.0   \n",
      "4           20.0               80.0                20.0          80.0   \n",
      "\n",
      "   cholesterol_imbalance  diabetes_risk  hypertension_risk  \\\n",
      "0                   80.0           27.5               80.0   \n",
      "1                   20.0           80.0               80.0   \n",
      "2                   20.0           30.8               80.0   \n",
      "3                   20.0           22.1               50.0   \n",
      "4                   80.0           30.2               80.0   \n",
      "\n",
      "   heart_disease_risk  obesity_risk  cholesterol_imbalance diabetes_risk_cat  \\\n",
      "0                20.0          20.0                   80.0               NaN   \n",
      "1                20.0          20.0                   20.0               NaN   \n",
      "2                20.0          50.0                   20.0               NaN   \n",
      "3                20.0          20.0                   20.0               NaN   \n",
      "4                20.0          80.0                   80.0               NaN   \n",
      "\n",
      "  hypertension_risk_cat heart_disease_risk_cat obesity_risk_cat  \\\n",
      "0                   NaN                    NaN              NaN   \n",
      "1                   NaN                    NaN              NaN   \n",
      "2                   NaN                    NaN              NaN   \n",
      "3                   NaN                    NaN              NaN   \n",
      "4                   NaN                    NaN              NaN   \n",
      "\n",
      "  cholesterol_imbalance_cat  \n",
      "0                       NaN  \n",
      "1                       NaN  \n",
      "2                       NaN  \n",
      "3                       NaN  \n",
      "4                       NaN  \n"
     ]
    }
   ],
   "source": [
    "# Combine true + predicted for inspection\n",
    "compare_df = pd.concat([y_test.reset_index(drop=True), pred_df.reset_index(drop=True),\n",
    "                        pred_cat_df.add_suffix(\"_cat\")], axis=1)\n",
    "print(\"\\nSample predictions (first 5 rows):\")\n",
    "print(compare_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "4191033c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved trained pipeline to /Users/tanya-mac/Desktop/Health Risk Predictor from Lifestyle & Medical History/models/multioutput_rf_pipeline.joblib\n"
     ]
    }
   ],
   "source": [
    "# ---------- 11) Save the pipeline ----------\n",
    "model_path = \"/Users/tanya-mac/Desktop/Health Risk Predictor from Lifestyle & Medical History/models/multioutput_rf_pipeline.joblib\"\n",
    "joblib.dump(pipe, model_path)\n",
    "print(f\"Saved trained pipeline to {model_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "fd2644b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Single example prediction:\n",
      "diabetes_risk: 28% (Low)\n",
      "hypertension_risk: 80% (Very High)\n",
      "heart_disease_risk: 20% (Low)\n",
      "obesity_risk: 20% (Low)\n",
      "cholesterol_imbalance: 80% (Very High)\n"
     ]
    }
   ],
   "source": [
    "# ---------- 12) Example single-patient prediction (use X_test.iloc[0]) ----------\n",
    "example_X = X_test.iloc[[0]]\n",
    "example_pred = pipe.predict(example_X)[0]  # array of 5 values\n",
    "example_pred_pct = example_pred  # already 0..100 in dataset convention\n",
    "example_pred_cat = [categorize(x) for x in example_pred_pct]\n",
    "\n",
    "print(\"\\nSingle example prediction:\")\n",
    "for name, pct, cat in zip(target_cols, example_pred_pct, example_pred_cat):\n",
    "    print(f\"{name}: {pct:.0f}% ({cat})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65fe0e20",
   "metadata": {},
   "source": [
    "# using LIGHTGBM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "48620ed0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting lightgbm\n",
      "  Downloading lightgbm-4.6.0-py3-none-macosx_12_0_arm64.whl.metadata (17 kB)\n",
      "Requirement already satisfied: numpy>=1.17.0 in /opt/anaconda3/envs/main/lib/python3.13/site-packages (from lightgbm) (2.3.5)\n",
      "Requirement already satisfied: scipy in /opt/anaconda3/envs/main/lib/python3.13/site-packages (from lightgbm) (1.16.3)\n",
      "Downloading lightgbm-4.6.0-py3-none-macosx_12_0_arm64.whl (1.6 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m1.8 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: lightgbm\n",
      "Successfully installed lightgbm-4.6.0\n"
     ]
    }
   ],
   "source": [
    "!pip install lightgbm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "72c1f212",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m==>\u001b[0m \u001b[1mAuto-updating Homebrew...\u001b[0m\n",
      "Adjust how often this is run with HOMEBREW_AUTO_UPDATE_SECS or disable with\n",
      "HOMEBREW_NO_AUTO_UPDATE. Hide these hints with HOMEBREW_NO_ENV_HINTS (see `man brew`).\n",
      "\u001b[34m==>\u001b[0m \u001b[1mDownloading https://ghcr.io/v2/homebrew/core/portable-ruby/blobs/sha256:c6946ba2c387b47934e77c352c2056489421003ec7ddb2abf246cef2168ec140\u001b[0m\n",
      "######################################################################### 100.0%                                                      9.3%                                              28.3%                                          45.1%########                                 58.0%###################                          68.2%#######           88.5%###########################         90.5%#############################        92.1%\n",
      "\u001b[34m==>\u001b[0m \u001b[1mPouring portable-ruby-3.4.7.arm64_big_sur.bottle.tar.gz\u001b[0m\n",
      "\u0007\u001b[34m==>\u001b[0m \u001b[1mHomebrew collects anonymous analytics.\u001b[0m\n",
      "\u001b[1mRead the analytics documentation (and how to opt-out) here:\n",
      "  \u001b[4mhttps://docs.brew.sh/Analytics\u001b[24m\u001b[0m\n",
      "No analytics have been recorded yet (nor will be during this `brew` run).\n",
      "\n",
      "\u001b[34m==>\u001b[0m \u001b[1mHomebrew is run entirely by unpaid volunteers. Please consider donating:\u001b[0m\n",
      "  \u001b[4mhttps://github.com/Homebrew/brew#donations\u001b[24m\n",
      "\n",
      "\u001b[34m==>\u001b[0m \u001b[1mAuto-updated Homebrew!\u001b[0m\n",
      "Updated 2 taps (homebrew/core and homebrew/cask).\n",
      "\u001b[34m==>\u001b[0m \u001b[1mNew Formulae\u001b[0m\n",
      "abpoa: SIMD-based C library for fast partial order alignment using adaptive band\n",
      "act_runner: Action runner for Gitea based on Gitea's fork of act\n",
      "addlicense: Scan directories recursively to ensure source files have license headers\n",
      "addons-linter: Firefox Add-ons linter, written in JavaScript\n",
      "aiac: Artificial Intelligence Infrastructure-as-Code Generator\n",
      "aicommit2: Reactive CLI that generates commit messages for Git and Jujutsu with AI\n",
      "aiken: Modern smart contract platform for Cardano\n",
      "air: Fast and opinionated formatter for R code\n",
      "airtable-mcp-server: MCP Server for Airtable\n",
      "aklomp-base64: Fast Base64 stream encoder/decoder in C99, with SIMD acceleration\n",
      "alejandra: Command-line tool for formatting Nix Code\n",
      "anchor: Solana Program Framework\n",
      "ansible@12: Automate deployment, configuration, and upgrading\n",
      "anyzig: Universal zig executable that runs any version of zig\n",
      "apache-polaris: Interoperable, open source catalog for Apache Iceberg\n",
      "apigeecli: Apigee management API command-line interface\n",
      "archgw: CLI for Arch Gateway\n",
      "arp-scan-rs: ARP scan tool written in Rust for fast local network scans\n",
      "asm-lsp: Language server for NASM/GAS/GO Assembly\n",
      "assimp@5: Portable library for importing many well-known 3D model formats\n",
      "atomic_queue: C++14 lock-free queues\n",
      "attempt-cli: CLI for retrying fallible commands\n",
      "audiowaveform: Generate waveform data and render waveform images from audio files\n",
      "autocycler: Tool for generating consensus long-read assemblies for bacterial genomes\n",
      "aws-lc: General-purpose cryptographic library\n",
      "aws-spiffe-workload-helper: Helper for providing AWS credentials to workloads using their SPIFFE identity\n",
      "ayatana-ido: Ayatana Indicator Display Objects\n",
      "b4: Tool to work with public-inbox and patch archives\n",
      "backgroundremover: Remove background from images and video using AI\n",
      "backlog-md: Markdown‑native Task Manager & Kanban visualizer for any Git repository\n",
      "badread: Long read simulator that can imitate many types of read problems\n",
      "bb-cli: Bitbucket Rest API CLI written in pure PHP\n",
      "bedtk: Simple toolset for BED files\n",
      "benchi: Benchmarking tool for data pipelines\n",
      "bento: Fancy stream processing made operationally mundane\n",
      "blueprint-compiler: Markup language and compiler for GTK 4 user interfaces\n",
      "boa: Embeddable and experimental Javascript engine written in Rust\n",
      "bom: Utility to generate SPDX-compliant Bill of Materials manifests\n",
      "breseq: Computational pipeline for finding mutations in short-read DNA resequencing data\n",
      "brush: Bourne RUsty SHell (command interpreter)\n",
      "bsc: Bluespec Compiler (BSC)\n",
      "bstring: Fork of Paul Hsieh's Better String Library\n",
      "btcli: Bittensor command-line tool\n",
      "btllib: Bioinformatics Technology Lab common code library\n",
      "bulletty: Pretty feed reader (ATOM/RSS) that stores articles in Markdown files\n",
      "bunster: Compile shell scripts to static binaries\n",
      "burrow: Kafka Consumer Lag Checking\n",
      "caesiumclt: Fast and efficient lossy and/or lossless image compression tool\n",
      "cagent: Agent Builder and Runtime by Docker Engineering\n",
      "cai: CLI tool for prompting LLMs\n",
      "cargo-careful: Execute Rust code carefully, with extra checking along the way\n",
      "cargo-clone: Cargo subcommand to fetch the source code of a Rust crate\n",
      "cargo-component: Create WebAssembly components based on the component model proposal\n",
      "cargo-geiger: Detects usage of unsafe Rust in a Rust crate and its dependencies\n",
      "ccusage: CLI tool for analyzing Claude Code usage from local JSONL files\n",
      "changelogen: Generate Beautiful Changelogs using Conventional Commits\n",
      "chawan: TUI web browser with CSS, inline image and JavaScript support\n",
      "chrome-devtools-mcp: Chrome DevTools for coding agents\n",
      "clang-include-graph: Simple tool for visualizing and analyzing C/C++ project include graph\n",
      "claude-cmd: Claude Code Commands Manager\n",
      "claude-code-router: Tool to route Claude Code requests to different models and customize any request\n",
      "claude-code-templates: CLI tool for configuring and monitoring Claude Code\n",
      "claude-hooks: Hook system for Claude Code\n",
      "claude-squad: Manage multiple AI agents like Claude Code, Aider and Codex in your terminal\n",
      "claudekit: Intelligent guardrails and workflow automation for Claude Code\n",
      "clipper2: Polygon clipping and offsetting library\n",
      "clippy: Copy files from your terminal that actually paste into GUI apps\n",
      "cliproxyapi: Wrap Gemini CLI, Codex, Claude Code, Qwen Code as an API service\n",
      "codebook-lsp: Code-aware spell checker language server\n",
      "cogapp: Small bits of Python computation for static files\n",
      "concurrentqueue: Fast multi-producer, multi-consumer lock-free concurrent queue for C++11\n",
      "config-file-validator: CLI tool to validate different configuration file types\n",
      "container: Create and run Linux containers using lightweight virtual machines\n",
      "container-canary: Test and validate container requirements against versioned manifests\n",
      "container-compose: Manage Apple Container with Docker Compose files\n",
      "context7-mcp: Up-to-date code documentation for LLMs and AI code editors\n",
      "copyparty: Portable file server\n",
      "corepack: Package acting as bridge between Node projects and their package managers\n",
      "cornelis: Neovim support for Agda\n",
      "cpptrace: Simple, portable, and self-contained stacktrace library for C++11 and newer\n",
      "cram: Functional testing framework for command-line applications\n",
      "crd2pulumi: Generate typed CustomResources from a Kubernetes CustomResourceDefinition\n",
      "credo: Static code analysis tool for the Elixir\n",
      "ctrld: Highly configurable, multi-protocol DNS forwarding proxy\n",
      "dagu: Lightweight and powerful workflow engine\n",
      "damask-grid: Grid solver of DAMASK - Multi-physics crystal plasticity simulation package\n",
      "darker: Apply Black formatting only in regions changed since last commit\n",
      "dash-mpd-cli: Download media content from a DASH-MPEG or DASH-WebM MPD manifest\n",
      "deck: Creates slide deck using Markdown and Google Slides\n",
      "decker: HyperCard-like multimedia sketchpad\n",
      "desed: Debugger for Sed\n",
      "devcockpit: TUI system monitor for Apple Silicon\n",
      "dexidp: OpenID Connect Identity and OAuth 2.0 Provider\n",
      "diagram: CLI app to convert ASCII arts into hand drawn diagrams\n",
      "dnglab: Camera RAW to DNG file format converter\n",
      "dnote: Simple command-line notebook\n",
      "docker-compose-langserver: Language service for Docker Compose documents\n",
      "docker-debug: Use new container attach on already container go on debug\n",
      "docmd: Minimal Markdown documentation generator\n",
      "doge: Command-line DNS client\n",
      "doh: Stand-alone DNS-over-HTTPS resolver using libcurl\n",
      "domain-check: CLI tool for checking domain availability using RDAP and WHOIS protocols\n",
      "doxx: Terminal document viewer for .docx files\n",
      "dqlite: Embeddable, replicated and fault-tolerant SQLite-powered engine\n",
      "dstp: Run common networking tests against your site\n",
      "dumbpipe: Unix pipes between devices\n",
      "dvisvgm: Fast DVI to SVG converter\n",
      "e1s: TUI for managing AWS ECS, inspired by k9s\n",
      "eask-cli: CLI for building, running, testing, and managing your Emacs Lisp dependencies\n",
      "eigen@3: C++ template library for linear algebra\n",
      "electric: Real-time sync for Postgres\n",
      "elf2uf2-rs: Convert ELF files to UF2 for USB Flashing Bootloaders\n",
      "emmylua_ls: Lua Language Server\n",
      "endlessh: SSH tarpit that slowly sends an endless banner\n",
      "entt: Fast and reliable entity-component system for C++\n",
      "erlang-language-platform: LSP server and CLI for the Erlang programming language\n",
      "erlang@27: Programming language for highly scalable real-time systems\n",
      "errcheck: Finds silently ignored errors in Go code\n",
      "execline: Interpreter-less scripting language\n",
      "execstack: Utility to set/clear/query executable stack bit\n",
      "faceprints: Detect and label images of faces using local Vision.framework models\n",
      "fake-gcs-server: Emulator for Google Cloud Storage API\n",
      "fakesteak: ASCII Matrix-like steak demo\n",
      "fastga: Pairwise whole genome aligner\n",
      "fastk: K-mer counter for high-fidelity shotgun datasets\n",
      "fastmcp: Fast, Pythonic way to build MCP servers and clients\n",
      "fastrace: Dependency-free traceroute implementation in pure C\n",
      "fennel-ls: Language Server for Fennel\n",
      "fernflower: Advanced decompiler for Java bytecode\n",
      "ffmate: FFmpeg automation layer\n",
      "ffmpeg@7: Play, record, convert, and stream audio and video\n",
      "filebrowser: Web File Browser\n",
      "filen-cli: Interface with Filen, an end-to-end encrypted cloud storage service\n",
      "fjira: Fuzzy-find cli jira interface\n",
      "flexget: Multipurpose automation tool for content\n",
      "flip-link: Adds zero-cost stack overflow protection to your embedded programs\n",
      "flye: De novo assembler for single molecule sequencing reads using repeat graphs\n",
      "fnox: Fort Knox for your secrets - flexible secret management tool\n",
      "forgejo: Self-hosted lightweight software forge\n",
      "forgejo-cli: CLI tool for interacting with Forgejo\n",
      "foxglove-cli: Foxglove command-line tool\n",
      "framework-tool-tui: TUI for controlling and monitoring Framework Computers hardware\n",
      "fx-upscale: Metal-powered video upscaling\n",
      "gbox: Provides environments for AI Agents to operate computer and mobile devices\n",
      "gcc@14: GNU compiler collection\n",
      "gcl: GNU Common Lisp\n",
      "gcli: Portable Git(hub|lab|tea)/Forgejo/Bugzilla CLI tool\n",
      "gemini-cli: Interact with Google Gemini AI models from the command-line\n",
      "gerust: Project generator for Rust backend projects\n",
      "getparty: Multi-part HTTP download manager\n",
      "ggc: Modern Git CLI\n",
      "ghalint: GitHub Actions linter\n",
      "ghidra: Multi-platform software reverse engineering framework\n",
      "git-xet: Git LFS plugin that uploads and downloads using the Xet protocol\n",
      "gitea-mcp-server: Interactive with Gitea instances with MCP\n",
      "gitingest: Turn any Git repository into a prompt-friendly text ingest for LLMs\n",
      "gitlab-ci-linter: Command-line tool to lint GitLab CI YAML files\n",
      "gitlab-release-cli: Toolset to create, retrieve and update releases on GitLab\n",
      "gitmux: Git status in tmux status bar\n",
      "gitnr: Create `.gitignore` using templates from TopTal, GitHub or your own collection\n",
      "glom: Declarative object transformer and formatter, for conglomerating nested data\n",
      "gnome-papers: Document viewer for PDF and other document formats aimed at the GNOME desktop\n",
      "go-librespot: Spotify client\n",
      "go-passbolt-cli: CLI for passbolt\n",
      "go-rice: Easily embed resources like HTML, JS, CSS, images, and templates in Go\n",
      "go@1.24: Open source programming language to build simple/reliable/efficient software\n",
      "gocheat: TUI Cheatsheet for keybindings, hotkeys and more\n",
      "goclone: Website Cloner\n",
      "gonzo: Log analysis TUI\n",
      "goodls: CLI tool to download shared files and folders from Google Drive\n",
      "goshs: Simple, yet feature-rich web server written in Go\n",
      "gotun: Lightweight HTTP proxy over SSH\n",
      "gpgmepp: C++ bindings for gpgme\n",
      "gpgmepy: Python bindings for gpgme\n",
      "gphotos-uploader-cli: Command-line tool to mass upload media folders to Google Photos\n",
      "gradle@8: Open-source build automation tool based on the Groovy and Kotlin DSL\n",
      "granted: Easiest way to access your cloud\n",
      "gravitino: High-performance, geo-distributed, and federated metadata lake\n",
      "gruyere: TUI program for viewing and killing processes listening on ports\n",
      "gtrash: Featureful Trash CLI manager: alternative to rm and trash-cli\n",
      "gwctl: CLI for managing and inspecting Gateway API resources in Kubernetes clusters\n",
      "hack-browser-data: Command-line tool for decrypting and exporting browser data\n",
      "hapless: Run and manage background processes\n",
      "haraka: Fast, highly extensible, and event driven SMTP server\n",
      "harbor-cli: CLI for Harbor container registry\n",
      "hdr10plus_tool: CLI utility to work with HDR10+ in HEVC files\n",
      "helm@3: Kubernetes package manager\n",
      "hexhog: Hex viewer/editor\n",
      "hf-mcp-server: MCP Server for Hugging Face\n",
      "hierarchy-builder: High level commands to declare a hierarchy based on packed classes\n",
      "htmlhint: Static code analysis tool you need for your HTML\n",
      "httptap: HTTP request visualizer with phase-by-phase timing breakdown\n",
      "hyper-mcp: MCP server that extends its capabilities through WebAssembly plugins\n",
      "icu4c@78: C/C++ and Java libraries for Unicode and globalization\n",
      "ifopt: Light-weight C++ Interface to Nonlinear Programming Solvers\n",
      "igrep: Interactive grep\n",
      "imagineer: Image processing and conversion from the terminal\n",
      "influxdb@2: Time series, events, and metrics database\n",
      "intelli-shell: Like IntelliSense, but for shells\n",
      "jiratui: Textual User Interface for interacting with Atlassian Jira from your shell\n",
      "jq-lsp: Jq language server\n",
      "jqp: TUI playground to experiment and play with jq\n",
      "jwt-hack: JSON Web Token Hack Toolkit\n",
      "kafkactl-aws-plugin: AWS Plugin for kafkactl\n",
      "kafkactl-azure-plugin: Azure Plugin for kafkactl\n",
      "kagent: Kubernetes native framework for building AI agents\n",
      "kanata-tray: System tray for kanata keyboard remapper\n",
      "kargo: Multi-Stage GitOps Continuous Promotion\n",
      "kbt: Keyboard tester in terminal\n",
      "kekkai: File integrity monitoring tool\n",
      "kibi: Text editor in ≤1024 lines of code, written in Rust\n",
      "kimi-cli: CLI agent for MoonshotAI Kimi platform\n",
      "kingfisher: MongoDB's blazingly fast secret scanning and validation tool\n",
      "kissat: Bare metal SAT solver\n",
      "kokkos: C++ Performance Portability Ecosystem for parallel execution and abstraction\n",
      "komac: Community Manifest Creator for Windows Package Manager (WinGet)\n",
      "kraken2: Taxonomic sequence classification system\n",
      "krane: Kubernetes deploy tool with rollout verification\n",
      "ktea: Kafka TUI client\n",
      "ktop: Top-like tool for your Kubernetes clusters\n",
      "kubernetes-cli@1.33: Kubernetes command-line interface\n",
      "kubernetes-mcp-server: MCP server for Kubernetes\n",
      "lakekeeper: Apache Iceberg REST Catalog\n",
      "lazycontainer: Terminal UI for Apple Containers\n",
      "lazyssh: Terminal-based SSH manager\n",
      "ldcli: CLI for managing LaunchDarkly feature flags\n",
      "libaegis: Portable C implementations of the AEGIS family of encryption algorithms\n",
      "libayatana-appindicator: Ayatana Application Indicators Shared Library\n",
      "libayatana-indicator: Ayatana Indicators Shared Library\n",
      "libbsc: High performance block-sorting data compression library\n",
      "libcaption: Free open-source CEA608 / CEA708 closed-caption encoder/decoder\n",
      "libcpucycles: Microlibrary for counting CPU cycles\n",
      "libdatrie: Double-Array Trie Library\n",
      "libdbusmenu: GLib and Gtk Implementation of the DBusMenu protocol\n",
      "libdecor: Client-side decorations library for Wayland client\n",
      "libjodycode: Shared code used by several utilities written by Jody Bruchon\n",
      "libngtcp2: IETF QUIC protocol implementation\n",
      "libpq@16: Postgres C API library\n",
      "libpq@17: Postgres C API library\n",
      "libptytty: Library for OS-independent pseudo-TTY management\n",
      "libselinux: SELinux library and simple utilities\n",
      "libsepol: SELinux binary policy manipulation library\n",
      "libudfread: Universal Disk Format reader\n",
      "lima-additional-guestagents: Additional guest agents for Lima\n",
      "limine: Modern, advanced, portable, multiprotocol bootloader and boot manager\n",
      "litehtml: Fast and lightweight HTML/CSS rendering engine\n",
      "lld@20: LLVM Project Linker\n",
      "llvm@20: Next-gen compiler infrastructure\n",
      "lnk: Git-native dotfiles management that doesn't suck\n",
      "lolcrab: Make your console colorful, with OpenSimplex noise\n",
      "lsr: Ls but with io_uring\n",
      "lstr: Fast, minimalist directory tree viewer\n",
      "lue-reader: Terminal eBook reader with text-to-speech and multi-format support\n",
      "lunarml: Standard ML compiler that produces Lua/JavaScript\n",
      "lunasvg: SVG rendering and manipulation library in C++\n",
      "lutgen: Blazingly fast interpolated LUT generator and applicator for color palettes\n",
      "lzsa: Lossless packer that is optimized for fast decompression on 8-bit micros\n",
      "mac-cleanup-py: Python cleanup script for macOS\n",
      "magika: Fast and accurate AI powered file content types detection\n",
      "mail-deduplicate: CLI to deduplicate mails from mail boxes\n",
      "manifold: Geometry library for topological robustness\n",
      "mariadb@11.8: Drop-in replacement for MySQL\n",
      "mark: Sync your markdown files with Confluence pages\n",
      "mbedtls@3: Cryptographic & SSL/TLS library\n",
      "mcat: Terminal image, video, directory, and Markdown viewer\n",
      "mcp-atlassian: MCP server for Atlassian tools (Confluence, Jira)\n",
      "mcp-get: CLI for discovering, installing, and managing MCP servers\n",
      "mcp-google-sheets: MCP server integrates with your Google Drive and Google Sheets\n",
      "mcp-grafana: MCP server for Grafana\n",
      "mcp-inspector: Visual testing tool for MCP servers\n",
      "mcp-proxy: Bridge between Streamable HTTP and stdio MCP transports\n",
      "mcp-publisher: Publisher CLI tool for the Official Model Context Protocol (MCP) Registry\n",
      "mcp-server-chart: MCP with 25+ @antvis charts for visualization, generation, and analysis\n",
      "mcp-server-kubernetes: MCP Server for kubernetes management commands\n",
      "mcphost: CLI host for LLMs to interact with tools via MCP\n",
      "mcptools: CLI for interacting with MCP servers using both stdio and HTTP transport\n",
      "mdfried: Terminal markdown viewer\n",
      "mdserve: Fast markdown preview server with live reload and theme support\n",
      "media-control: Control and observe media playback from the command-line\n",
      "melt: Backup and restore Ed25519 SSH keys with seed words\n",
      "memtier_benchmark: Redis and Memcache traffic generation and benchmarking tool\n",
      "mermaid-cli: CLI for Mermaid library\n",
      "min-lang: Small but practical concatenative programming language and shell\n",
      "minify: Minifier for HTML, CSS, JS, JSON, SVG, and XML\n",
      "miniprot: Align proteins to genomes with splicing and frameshift\n",
      "mitama-cpp-result: Provides `result<T, E>` and `maybe<T>` and monadic functions for them\n",
      "mk: Wrapper for auto-detecting build and test commands in a repository\n",
      "mklittlefs: Creates LittleFS images for ESP8266, ESP32, Pico RP2040, and RP2350\n",
      "mlc: Check for broken links in markup files\n",
      "mlx-lm: Run LLMs with MLX\n",
      "mongo-c-driver@1: C driver for MongoDB\n",
      "moodle-dl: Downloads course content fast from Moodle (e.g., lecture PDFs)\n",
      "moribito: TUI for LDAP Viewing/Queries\n",
      "mpremote: Tool for interacting remotely with MicroPython devices\n",
      "msedit: Simple text editor with clickable interface\n",
      "msolve: Library for Polynomial System Solving through Algebraic Methods\n",
      "mysql-to-sqlite3: Transfer data from MySQL to SQLite\n",
      "n8n-mcp: MCP for Claude Desktop, Claude Code, Windsurf, Cursor to build n8n workflows\n",
      "nanoarrow: Helpers for Arrow C Data & Arrow C Stream interfaces\n",
      "nanobot: Build MCP Agents\n",
      "nessie: Transactional Catalog for Data Lakes with Git-like semantics\n",
      "netscanner: Network scanner with features like WiFi scanning, packetdump and more\n",
      "nextflow: Reproducible scientific workflows\n",
      "ni: Selects the right Node package manager based on lockfiles\n",
      "nifi-toolkit: Command-line utilities to setup and support NiFi\n",
      "nixfmt: Command-line tool to format Nix language code\n",
      "node@24: Open-source, cross-platform JavaScript runtime environment\n",
      "notion-mcp-server: MCP Server for Notion\n",
      "npq: Audit npm packages before you install them\n",
      "nuxi: Nuxt CLI (nuxi) for creating and managing Nuxt projects\n",
      "nx: Smart, Fast and Extensible Build System\n",
      "nyan: Colorizing `cat` command with syntax highlighting\n",
      "oasis: CLI for interacting with the Oasis Protocol network\n",
      "oatpp: Light and powerful C++ web framework\n",
      "omekasy: Converts alphanumeric input to various Unicode styles\n",
      "omnara: Talk to Your AI Agents from Anywhere\n",
      "onigmo: Regular expressions library forked from Oniguruma\n",
      "openapi: CLI tools for working with OpenAPI, Arazzo and Overlay specifications\n",
      "openapv: Open Advanced Professional Video Codec\n",
      "openblas64: Optimized BLAS library\n",
      "opencode: AI coding agent, built for the terminal\n",
      "openlist: New AList fork addressing anti-trust issues\n",
      "openssl@3.5: Cryptography and SSL/TLS Toolkit\n",
      "osx-trash: Allows trashing of files instead of tempting fate with rm\n",
      "oterm: Terminal client for Ollama\n",
      "ovsx: Command-line interface for Eclipse Open VSX\n",
      "oxen: Data VCS for structured and unstructured machine learning datasets\n",
      "pangene: Construct pangenome gene graphs\n",
      "parqeye: Peek inside Parquet files right from your terminal\n",
      "pdtm: ProjectDiscovery's Open Source Tool Manager\n",
      "pelican: Static site generator that supports Markdown and reST syntax\n",
      "perbase: Fast and correct perbase BAM/CRAM analysis\n",
      "permify: Open-source authorization service & policy engine based on Google Zanzibar\n",
      "pg-schema-diff: Diff Postgres schemas and generating SQL migrations\n",
      "pgslice: Postgres partitioning as easy as pie\n",
      "pgstream: PostgreSQL replication with DDL changes\n",
      "php-intl: PHP internationalization extension\n",
      "php@8.4: General-purpose scripting language\n",
      "pipewire: Server and user space API to deal with multimedia pipelines\n",
      "plakar: Create backups with compression, encryption and deduplication\n",
      "playwright-mcp: MCP server for Playwright\n",
      "plutobook: Paged HTML Rendering Library\n",
      "plutoprint: Generate PDFs and Images from HTML\n",
      "plutovg: Tiny 2D vector graphics library in C\n",
      "podcast-archiver: Archive all episodes from your favorite podcasts\n",
      "polaris: Validation of best practices in your Kubernetes clusters\n",
      "polypolish: Short-read polishing tool for long-read assemblies\n",
      "portable-libffi: Portable Foreign Function Interface library\n",
      "portable-libxcrypt: Extended crypt library for descrypt, md5crypt, bcrypt, and others\n",
      "portable-libyaml: YAML Parser\n",
      "portable-openssl: Cryptography and SSL/TLS Toolkit\n",
      "portable-ruby: Powerful, clean, object-oriented scripting language\n",
      "portable-zlib: General-purpose lossless data-compression library\n",
      "postgres-language-server: Language Server for Postgres\n",
      "postgresql@18: Object-relational database system\n",
      "precice: Coupling library for partitioned multi-physics simulations\n",
      "privatebin-cli: CLI for creating and managing PrivateBin pastes\n",
      "protozero: Minimalist protocol buffer decoder and encoder in C++\n",
      "pulp-cli: Command-line interface for Pulp 3\n",
      "pulumictl: Swiss army knife for Pulumi development\n",
      "pyrefly: Fast type checker and IDE for Python\n",
      "pyscn: Intelligent Python Code Quality Analyzer\n",
      "python-gdbm@3.14: Python interface to gdbm\n",
      "python-tk@3.14: Python interface to Tcl/Tk\n",
      "python@3.14: Interpreted, interactive, object-oriented programming language\n",
      "pytr: Use TradeRepublic in terminal and mass download all documents\n",
      "q: Tiny command-line DNS client with support for UDP, TCP, DoT, DoH, DoQ and ODoH\n",
      "qcoro6: C++ Coroutines for Qt\n",
      "qman: Modern man page viewer\n",
      "qnm: CLI for querying the node_modules directory\n",
      "qrkey: Generate and recover QR codes from files for offline private key backup\n",
      "qt3d: Provides functionality for near-realtime simulation systems\n",
      "qt5compat: Qt 5 Core APIs that were removed in Qt 6\n",
      "qtbase: Cross-platform application and UI framework\n",
      "qtcharts: UI Components for displaying visually pleasing charts\n",
      "qtconnectivity: Provides access to Bluetooth hardware\n",
      "qtdatavis3d: Provides functionality for 3D visualization\n",
      "qtdeclarative: QML, Qt Quick and several related modules\n",
      "qtgraphs: Provides functionality for 2D and 3D graphs\n",
      "qtgrpc: Provides support for communicating with gRPC services\n",
      "qthttpserver: Framework for embedding an HTTP server into a Qt application\n",
      "qtimageformats: Plugins for additional image formats: TIFF, MNG, TGA, WBMP\n",
      "qtlanguageserver: Implementation of the Language Server Protocol and JSON-RPC\n",
      "qtlocation: Provides C++ interfaces to retrieve location and navigational information\n",
      "qtlottie: Display graphics and animations exported by the Bodymovin plugin\n",
      "qtmultimedia: Provides APIs for playing back and recording audiovisual content\n",
      "qtnetworkauth: Provides support for OAuth-based authorization to online services\n",
      "qtpositioning: Provides access to position, satellite info and area monitoring classes\n",
      "qtquick3d: Provides a high-level API for creating 3D content or UIs based on Qt Quick\n",
      "qtquick3dphysics: High-level QML module adding physical simulation capabilities to Qt Quick 3D\n",
      "qtquickeffectmaker: Tool to create custom Qt Quick shader effects\n",
      "qtquicktimeline: Enables keyframe-based animations and parameterization\n",
      "qtremoteobjects: Provides APIs for inter-process communication\n",
      "qtscxml: Provides functionality to create state machines from SCXML files\n",
      "qtsensors: Provides access to sensors via QML and C++ interfaces\n",
      "qtserialbus: Provides access to serial industrial bus interfaces\n",
      "qtserialport: Provides classes to interact with hardware and virtual serial ports\n",
      "qtshadertools: Provides tools for the cross-platform Qt shader pipeline\n",
      "qtspeech: Enables access to text-to-speech engines\n",
      "qtsvg: Classes for displaying the contents of SVG files\n",
      "qttools: Facilitate the design, development, testing and deployment of applications\n",
      "qttranslations: Qt translation catalogs\n",
      "qtvirtualkeyboard: Provides an input framework and reference keyboard frontend\n",
      "qtwayland: Wayland platform plugin and QtWaylandCompositor API\n",
      "qtwebchannel: Bridges the gap between Qt applications and HTML/JavaScript\n",
      "qtwebengine: Provides functionality for rendering regions of dynamic web content\n",
      "qtwebsockets: Provides WebSocket communication compliant with RFC 6455\n",
      "qtwebview: Displays web content in a QML application\n",
      "quadcastrgb: Set RGB lights on HyperX QuadCast S and Duocast microphones\n",
      "quint: Core tool for the Quint specification language\n",
      "qwen-code: AI-powered command-line workflow tool for developers\n",
      "radvd: IPv6 Router Advertisement Daemon\n",
      "rails-mcp-server: MCP server for Rails applications\n",
      "rasusa: Randomly subsample sequencing reads or alignments\n",
      "readsb: ADS-B decoder swiss knife\n",
      "reckoner: Declaratively install and manage multiple Helm chart releases\n",
      "recur: Retry a command with exponential backoff and jitter\n",
      "reddix: Reddit, refined for the terminal\n",
      "redis@8.2: Persistent key-value database, with built-in net interface\n",
      "resterm: Terminal client for .http/.rest files with HTTP, GraphQL, and gRPC support\n",
      "rggen: Code generation tool for control and status registers\n",
      "rmpc: Terminal based Media Player Client with album art support\n",
      "rna-star: RNA-seq aligner\n",
      "rnp: High performance C++ OpenPGP library used by Mozilla Thunderbird\n",
      "rocq-elpi: Elpi extension language for Rocq\n",
      "rolesanywhere-credential-helper: Manages getting temporary security credentials from IAM Roles Anywhere\n",
      "ropebwt3: BWT construction and search\n",
      "rqbit: Fast command-line bittorrent client and server\n",
      "rsql: CLI for relational databases and common data file formats\n",
      "rulesync: Unified AI rules management CLI tool\n",
      "rumdl: Markdown Linter and Formatter written in Rust\n",
      "rv: Ruby version manager\n",
      "s6-rc: Process supervision suite\n",
      "salesforce-mcp: MCP Server for interacting with Salesforce instances\n",
      "samply: CLI sampling profiler\n",
      "sarif-tools: Set of command-line tools and Python library for working with SARIF files\n",
      "scdl: Command-line tool to download music from SoundCloud\n",
      "secretspec: Declarative secrets management tool\n",
      "seqan3: Modern C++ library for sequence analysis\n",
      "shamrock: Astrophysical hydrodynamics using SYCL\n",
      "sherif: Opinionated, zero-config linter for JavaScript monorepos\n",
      "shimmy: Small local inference server with OpenAI-compatible GGUF endpoints\n",
      "shortest: AI-powered natural language end-to-end testing framework\n",
      "skalibs: Skarnet's library collection\n",
      "skani: Fast, robust ANI and aligned fraction for (metagenomic) genomes and contigs\n",
      "slack-mcp-server: Powerful MCP Slack Server with multiple transports and smart history fetch logic\n",
      "snooze: Run a command at a particular time\n",
      "somo: Human-friendly alternative to netstat for socket and port monitoring\n",
      "sox_ng: Sound eXchange NG\n",
      "specify: Toolkit to help you get started with Spec-Driven Development\n",
      "spice-server: Implements the server side of the SPICE protocol\n",
      "spiffe-helper: Tool that can be used to retrieve and manage SVIDs on behalf of a workload\n",
      "sprocket: Bioinformatics workflow engine built on the Workflow Description Language (WDL)\n",
      "sqlite-rsync: SQLite remote copy tool\n",
      "sqlite3-to-mysql: Transfer data from SQLite to MySQL\n",
      "sqruff: Fast SQL formatter/linter\n",
      "standardebooks: Tools for producing ebook files\n",
      "stormy: Minimal, customizable and neofetch-like weather CLI based on rainy\n",
      "strands-agents-sops: Standard Operating Procedures for AI agents using natural language\n",
      "stringtie: Transcript assembly and quantification for RNA-Seq\n",
      "stu: TUI explorer application for Amazon S3 (AWS S3)\n",
      "style-dictionary: Build system for creating cross-platform styles\n",
      "supabase: Open source Firebase alternative\n",
      "supabase-mcp-server: MCP Server for Supabase\n",
      "swag: Automatically generate RESTful API documentation with Swagger 2.0 for Go\n",
      "swift-section: CLI tool for parsing mach-o files to obtain Swift information\n",
      "sylph: Ultrafast taxonomic profiling and genome querying for metagenomic samples\n",
      "tabixpp: C++ wrapper to tabix indexer\n",
      "taskline: Tasks, boards & notes for the command-line habitat\n",
      "taze: Modern cli tool that keeps your deps fresh\n",
      "tdd-guard: Automated TDD enforcement for Claude Code\n",
      "teamtype: Peer-to-peer, editor-agnostic collaborative editing of local text files\n",
      "termsvg: Record, share and export your terminal as a animated SVG image\n",
      "terraform-mcp-server: MCP server for Terraform\n",
      "terratag: CLI to automate tagging for AWS, Azure & GCP resources in Terraform\n",
      "teslamate: Self-hosted data logger for your Tesla\n",
      "tfmcp: Terraform Model Context Protocol (MCP) Tool\n",
      "tfplugingen-openapi: OpenAPI to Terraform Provider Code Generation Specification\n",
      "tfstate-lookup: Lookup resource attributes in tfstate\n",
      "tiledb: Universal storage engine\n",
      "tiny-remapper: Tiny, efficient tool for remapping JAR files using \"Tiny\"-format mappings\n",
      "tkrzw: Set of implementations of DBM\n",
      "tldx: Domain Availability Research Tool\n",
      "tofu-ls: OpenTofu Language Server\n",
      "tombi: TOML formatter, linter and language server\n",
      "toml-bombadil: Dotfile manager with templating\n",
      "torrra: Find and download torrents without leaving your CLI\n",
      "tracetest: Build integration and end-to-end tests\n",
      "tree-sitter-cli: Parser generator tool\n",
      "trimal: Automated alignment trimming in large-scale phylogenetic analyses\n",
      "ts_query_ls: LSP implementation for Tree-sitter's query files\n",
      "tscriptify: Golang struct to TypeScript class/interface converter\n",
      "tsnet-serve: Expose HTTP applications to a Tailscale Tailnet network\n",
      "tuios: Terminal UI OS (Terminal Multiplexer)\n",
      "tun2proxy: Tunnel (TUN) interface for SOCKS and HTTP proxies\n",
      "tweakcc: Customize your Claude Code themes, thinking verbs, and more\n",
      "two-ms: Detect secrets in files and communication platforms\n",
      "typtea: Minimal terminal-based typing speed tester\n",
      "unitycatalog: Open, Multi-modal Catalog for Data & AI\n",
      "urx: Extracts URLs from OSINT Archives for Security Insights\n",
      "uvwasi: WASI syscall API built atop libuv\n",
      "varlock: Add declarative schema to .env files using @env-spec decorator comments\n",
      "vgo: Project scaffolder for Go, written in Go\n",
      "vibe-log-cli: CLI tool for analyzing Claude Code sessions\n",
      "vibecheck: AI-powered git commit assistant written in Go\n",
      "videoalchemy: Toolkit expanding video processing capabilities\n",
      "vineflower: Java decompiler\n",
      "volcano-cli: CLI for Volcano, Cloud Native Batch System\n",
      "vsd: Download video streams over HTTP, DASH (.mpd), and HLS (.m3u8)\n",
      "vtcode: CLI Semantic Coding Agent\n",
      "wait4x: Wait for a port or a service to enter the requested state\n",
      "wal-g: Archival restoration tool for databases\n",
      "wassette: Security-oriented runtime that runs WebAssembly Components via MCP\n",
      "wayback: Archiving tool integrated with various archival services\n",
      "webdav: Simple and standalone WebDAV server\n",
      "wgpu-native: Native WebGPU implementation based on wgpu-core\n",
      "wishlist: Single entrypoint for multiple SSH endpoints\n",
      "wuppiefuzz: Coverage-guided REST API fuzzer developed on top of LibAFL\n",
      "wxwidgets@3.2: Cross-platform C++ GUI toolkit\n",
      "xcp: Fast & lightweight command-line tool for managing Xcode projects, built in Swift\n",
      "xleak: Terminal Excel viewer with an interactive TUI\n",
      "yaml2json: Command-line tool convert from YAML to JSON\n",
      "yamlresume: Resumes as code in YAML\n",
      "yek: Fast Rust based tool to serialize text-based files for LLM consumption\n",
      "yuque-dl: Knowledge base downloader for Yuque\n",
      "zig@0.14: Programming language designed for robustness, optimality, and clarity\n",
      "zsh-history-enquirer: Zsh plugin that enhances history search interaction\n",
      "zsv: Tabular data swiss-army knife CLI\n",
      "zuban: Python language server and type checker, written in Rust\n",
      "\n",
      "You have \u001b[1m4\u001b[0m outdated formulae installed.\n",
      "\n",
      "\u001b[32m==>\u001b[0m \u001b[1mFetching downloads for: \u001b[32mlibomp\u001b[39m\u001b[0m\n",
      "\u001b[?25l\u001b[K\u001b[34m⠋\u001b[0m Bottle Manifest libomp (21.1.6)\u001b[0G\u001b[K\u001b[34m⠋\u001b[0m Bottle Manifest libomp (21.1.6)\u001b[0G\u001b[K\u001b[34m⠙\u001b[0m Bottle Manifest libomp (21.1.6)\u001b[0G\u001b[K\u001b[34m⠙\u001b[0m Bottle Manifest libomp (21.1.6)\u001b[0G\u001b[K\u001b[34m⠚\u001b[0m Bottle Manifest libomp (21.1.6)\u001b[0G\u001b[K\u001b[34m⠚\u001b[0m Bottle Manifest libomp (21.1.6)\u001b[0G\u001b[K\u001b[34m⠞\u001b[0m Bottle Manifest libomp (21.1.6)\u001b[0G\u001b[K\u001b[34m⠞\u001b[0m Bottle Manifest libomp (21.1.6)\u001b[0G\u001b[K\u001b[34m⠖\u001b[0m Bottle Manifest libomp (21.1.6)\u001b[0G\u001b[K\u001b[34m⠖\u001b[0m Bottle Manifest libomp (21.1.6)\u001b[0G\u001b[K\u001b[34m⠦\u001b[0m Bottle Manifest libomp (21.1.6)                  [Downloading   8.2KB/-------]\u001b[0G\u001b[K\u001b[34m⠦\u001b[0m Bottle Manifest libomp (21.1.6)                  [Downloading   8.2KB/-------]\u001b[0G\u001b[K\u001b[34m⠴\u001b[0m Bottle Manifest libomp (21.1.6)                  [Downloading   8.2KB/-------]\u001b[0G\u001b[K\u001b[34m⠴\u001b[0m Bottle Manifest libomp (21.1.6)                  [Downloading   8.2KB/-------]\u001b[0G\u001b[K\u001b[32m✔︎\u001b[0m Bottle Manifest libomp (21.1.6)                  [Downloaded   11.9KB/ 11.9KB]\n",
      "\u001b[?25h\u001b[?25l\u001b[K\u001b[34m⠲\u001b[0m Bottle libomp (21.1.6)\u001b[0G\u001b[K\u001b[34m⠲\u001b[0m Bottle libomp (21.1.6)\u001b[0G\u001b[K\u001b[34m⠳\u001b[0m Bottle libomp (21.1.6)\u001b[0G\u001b[K\u001b[34m⠳\u001b[0m Bottle libomp (21.1.6)\u001b[0G\u001b[K\u001b[34m⠓\u001b[0m Bottle libomp (21.1.6)\u001b[0G\u001b[K\u001b[34m⠓\u001b[0m Bottle libomp (21.1.6)\u001b[0G\u001b[K\u001b[34m⠋\u001b[0m Bottle libomp (21.1.6)\u001b[0G\u001b[K\u001b[34m⠋\u001b[0m Bottle libomp (21.1.6)\u001b[0G\u001b[K\u001b[34m⠙\u001b[0m Bottle libomp (21.1.6)\u001b[0G\u001b[K\u001b[34m⠙\u001b[0m Bottle libomp (21.1.6)\u001b[0G\u001b[K\u001b[34m⠚\u001b[0m Bottle libomp (21.1.6)\u001b[0G\u001b[K\u001b[34m⠚\u001b[0m Bottle libomp (21.1.6)\u001b[0G\u001b[K\u001b[34m⠞\u001b[0m Bottle libomp (21.1.6)\u001b[0G\u001b[K\u001b[34m⠞\u001b[0m Bottle libomp (21.1.6)\u001b[0G\u001b[K\u001b[34m⠖\u001b[0m Bottle libomp (21.1.6)\u001b[0G\u001b[K\u001b[34m⠖\u001b[0m Bottle libomp (21.1.6)\u001b[0G\u001b[K\u001b[34m⠦\u001b[0m Bottle libomp (21.1.6)\u001b[0G\u001b[K\u001b[34m⠦\u001b[0m Bottle libomp (21.1.6)\u001b[0G\u001b[K\u001b[34m⠴\u001b[0m Bottle libomp (21.1.6)\u001b[0G\u001b[K\u001b[34m⠴\u001b[0m Bottle libomp (21.1.6)\u001b[0G\u001b[K\u001b[34m⠲\u001b[0m Bottle libomp (21.1.6)\u001b[0G\u001b[K\u001b[34m⠲\u001b[0m Bottle libomp (21.1.6)\u001b[0G\u001b[K\u001b[34m⠳\u001b[0m Bottle libomp (21.1.6)\u001b[0G\u001b[K\u001b[34m⠳\u001b[0m Bottle libomp (21.1.6)\u001b[0G\u001b[K\u001b[34m⠓\u001b[0m Bottle libomp (21.1.6)                           [Downloading  24.6KB/586.2KB]\u001b[0G\u001b[K\u001b[34m⠓\u001b[0m Bottle libomp (21.1.6)                           [Downloading  45.1KB/586.2KB]\u001b[0G\u001b[K\u001b[34m⠋\u001b[0m Bottle libomp (21.1.6)                           [Downloading  61.4KB/586.2KB]\u001b[0G\u001b[K\u001b[34m⠋\u001b[0m Bottle libomp (21.1.6)                           [Downloading  94.2KB/586.2KB]\u001b[0G\u001b[K\u001b[34m⠙\u001b[0m Bottle libomp (21.1.6)                           [Downloading 143.4KB/586.2KB]\u001b[0G\u001b[K\u001b[34m⠙\u001b[0m Bottle libomp (21.1.6)                           [Downloading 192.5KB/586.2KB]\u001b[0G\u001b[K\u001b[34m⠚\u001b[0m Bottle libomp (21.1.6)                           [Downloading 258.0KB/586.2KB]\u001b[0G\u001b[K\u001b[34m⠚\u001b[0m Bottle libomp (21.1.6)                           [Downloading 290.8KB/586.2KB]\u001b[0G\u001b[K\u001b[34m⠞\u001b[0m Bottle libomp (21.1.6)                           [Downloading 356.4KB/586.2KB]\u001b[0G\u001b[K\u001b[34m⠞\u001b[0m Bottle libomp (21.1.6)                           [Downloading 389.1KB/586.2KB]\u001b[0G\u001b[K\u001b[34m⠖\u001b[0m Bottle libomp (21.1.6)                           [Downloading 421.9KB/586.2KB]\u001b[0G\u001b[K\u001b[34m⠖\u001b[0m Bottle libomp (21.1.6)                           [Downloading 421.9KB/586.2KB]\u001b[0G\u001b[K\u001b[34m⠦\u001b[0m Bottle libomp (21.1.6)                           [Downloading 503.8KB/586.2KB]\u001b[0G\u001b[K\u001b[34m⠦\u001b[0m Bottle libomp (21.1.6)                           [Downloading 520.2KB/586.2KB]\u001b[0G\u001b[K\u001b[34m⠴\u001b[0m Bottle libomp (21.1.6)                           [Downloading 569.3KB/586.2KB]\u001b[0G\u001b[K\u001b[32m✔︎\u001b[0m Bottle libomp (21.1.6)                           [Downloaded  586.2KB/586.2KB]\n",
      "\u001b[?25h\u001b[34m==>\u001b[0m \u001b[1mPouring libomp--21.1.6.arm64_tahoe.bottle.tar.gz\u001b[0m\n",
      "\u001b[34m==>\u001b[0m \u001b[1mCaveats\u001b[0m\n",
      "libomp is keg-only, which means it was not symlinked into /opt/homebrew,\n",
      "because it can override GCC headers and result in broken builds.\n",
      "\n",
      "For compilers to find libomp you may need to set:\n",
      "  export LDFLAGS=\"-L/opt/homebrew/opt/libomp/lib\"\n",
      "  export CPPFLAGS=\"-I/opt/homebrew/opt/libomp/include\"\n",
      "\u001b[34m==>\u001b[0m \u001b[1mSummary\u001b[0m\n",
      "🍺  /opt/homebrew/Cellar/libomp/21.1.6: 9 files, 1.8MB\n",
      "\u001b[34m==>\u001b[0m \u001b[1mRunning `brew cleanup libomp`...\u001b[0m\n",
      "Disable this behaviour by setting `HOMEBREW_NO_INSTALL_CLEANUP=1`.\n",
      "Hide these hints with `HOMEBREW_NO_ENV_HINTS=1` (see `man brew`).\n",
      "\u001b[32m==>\u001b[0m \u001b[1m`brew cleanup` has not been run in the last 30 days, running now...\u001b[0m\n",
      "Disable this behaviour by setting `HOMEBREW_NO_INSTALL_CLEANUP=1`.\n",
      "Hide these hints with `HOMEBREW_NO_ENV_HINTS=1` (see `man brew`).\n",
      "Removing: /Users/tanya-mac/Library/Caches/Homebrew/gettext_bottle_manifest--0.25... (15.3KB)\n",
      "Removing: /Users/tanya-mac/Library/Caches/Homebrew/gettext--0.25... (9.4MB)\n",
      "Removing: /Users/tanya-mac/Library/Caches/Homebrew/git_bottle_manifest--2.49.0... (20.1KB)\n",
      "Removing: /Users/tanya-mac/Library/Caches/Homebrew/git--2.49.0... (20.9MB)\n",
      "Removing: /Users/tanya-mac/Library/Caches/Homebrew/libunistring_bottle_manifest--1.3... (8.3KB)\n",
      "Removing: /Users/tanya-mac/Library/Caches/Homebrew/libunistring--1.3... (1.8MB)\n",
      "Removing: /Users/tanya-mac/Library/Caches/Homebrew/pcre2_bottle_manifest--10.45... (10.5KB)\n",
      "Removing: /Users/tanya-mac/Library/Caches/Homebrew/pcre2--10.45... (2.3MB)\n",
      "Removing: /Users/tanya-mac/Library/Caches/Homebrew/portable-ruby-3.4.3.arm64_big_sur.bottle.tar.gz... (12.0MB)\n",
      "Removing: /Users/tanya-mac/Library/Caches/Homebrew/bootsnap/db179102286f8d8c783210e6c7fc906399381061d0aacd5d2af9f9dbe5c14e9b... (564 files, 4.9MB)\n",
      "Found existing installation: lightgbm 4.6.0\n",
      "Uninstalling lightgbm-4.6.0:\n",
      "  Successfully uninstalled lightgbm-4.6.0\n",
      "Collecting lightgbm\n",
      "  Using cached lightgbm-4.6.0-py3-none-macosx_12_0_arm64.whl.metadata (17 kB)\n",
      "Requirement already satisfied: numpy>=1.17.0 in /opt/anaconda3/envs/main/lib/python3.13/site-packages (from lightgbm) (2.3.5)\n",
      "Requirement already satisfied: scipy in /opt/anaconda3/envs/main/lib/python3.13/site-packages (from lightgbm) (1.16.3)\n",
      "Using cached lightgbm-4.6.0-py3-none-macosx_12_0_arm64.whl (1.6 MB)\n",
      "Installing collected packages: lightgbm\n",
      "Successfully installed lightgbm-4.6.0\n"
     ]
    }
   ],
   "source": [
    "# install libomp\n",
    "!brew install libomp\n",
    "\n",
    "# then reinstall lightgbm (so it links correctly)\n",
    "!pip uninstall -y lightgbm\n",
    "!pip install lightgbm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "6b5fae43",
   "metadata": {},
   "outputs": [],
   "source": [
    "from lightgbm import LGBMRegressor\n",
    "from sklearn.multioutput import MultiOutputRegressor\n",
    "\n",
    "base_lgb = LGBMRegressor(\n",
    "    n_estimators=1000,\n",
    "    learning_rate=0.05,\n",
    "    subsample=0.8,\n",
    "    colsample_bytree=0.8,\n",
    "    random_state=42,\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "multi_model = MultiOutputRegressor(base_lgb, n_jobs=-1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "af756b35",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe_1 = Pipeline([\n",
    "    ('preprocess', preprocessor),\n",
    "    ('model', multi_model)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "451840e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting pipeline ...\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.014704 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 2711\n",
      "[LightGBM] [Info] Number of data points in the train set: 72972, number of used features: 39\n",
      "[LightGBM] [Info] Start training from score 55.958724\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.013583 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2711\n",
      "[LightGBM] [Info] Number of data points in the train set: 72972, number of used features: 39\n",
      "[LightGBM] [Info] Start training from score 23.910541\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.014111 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2711\n",
      "[LightGBM] [Info] Number of data points in the train set: 72972, number of used features: 39\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.014895 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2711\n",
      "[LightGBM] [Info] Number of data points in the train set: 72972, number of used features: 39\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.015179 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Start training from score 51.007236\n",
      "[LightGBM] [Info] Start training from score 56.819602\n",
      "[LightGBM] [Info] Total Bins 2711\n",
      "[LightGBM] [Info] Number of data points in the train set: 72972, number of used features: 39\n",
      "[LightGBM] [Info] Start training from score 30.014800\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Training finished.\n"
     ]
    }
   ],
   "source": [
    "print(\"Fitting pipeline ...\")\n",
    "pipe_1.fit(X_train, y_train)\n",
    "print(\"Training finished.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "a71377cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_1 = pipe.predict(X_test)  # shape (n_samples, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "920ce5cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "diabetes_risk -> MAE: 8.155, RMSE: 15.484, R2: 0.722\n",
      "hypertension_risk -> MAE: 0.000, RMSE: 0.000, R2: 1.000\n",
      "heart_disease_risk -> MAE: 0.021, RMSE: 0.688, R2: 0.998\n",
      "obesity_risk -> MAE: 0.000, RMSE: 0.000, R2: 1.000\n",
      "cholesterol_imbalance -> MAE: 0.000, RMSE: 0.000, R2: 1.000\n",
      "Mean MAE across targets: 1.635\n"
     ]
    }
   ],
   "source": [
    "metrics = {}\n",
    "for i, col in enumerate(target_cols):\n",
    "    mae = mean_absolute_error(y_test.iloc[:, i], y_pred_1[:, i])\n",
    "    rmse = np.sqrt(mean_squared_error(y_test.iloc[:, i], y_pred_1[:, i] ))\n",
    "    r2 = r2_score(y_test.iloc[:, i], y_pred_1[:, i])\n",
    "    metrics[col] = {\"MAE\": mae, \"RMSE\": rmse, \"R2\": r2}\n",
    "    print(f\"{col} -> MAE: {mae:.3f}, RMSE: {rmse:.3f}, R2: {r2:.3f}\")\n",
    "\n",
    "# overall (mean MAE)\n",
    "mean_mae = np.mean([m[\"MAE\"] for m in metrics.values()])\n",
    "print(f\"Mean MAE across targets: {mean_mae:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ddcf303",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "main",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
